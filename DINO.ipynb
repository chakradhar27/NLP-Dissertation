{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DINO.ipynb","provenance":[],"collapsed_sections":["UK-0pVy9Wtei","sSBJMIQOvt9n","FCrI2yzBUvyU","zK78QQsbWbDO"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"orR8enw2W5XA"},"source":["# Preprocessing Steps and installation of resources"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L3KKeQ5Tv2Tt","executionInfo":{"status":"ok","timestamp":1630492255278,"user_tz":-60,"elapsed":26307,"user":{"displayName":"varma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0mykgB2BlfeZ8lmORSdRPDRvODaQ8LpLMBHSi3Q=s64","userId":"17507925689662955290"}},"outputId":"50699246-407e-4138-ff26-7741b387e673"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FgxG4b4CxFVi","executionInfo":{"status":"ok","timestamp":1630492267620,"user_tz":-60,"elapsed":456,"user":{"displayName":"varma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0mykgB2BlfeZ8lmORSdRPDRvODaQ8LpLMBHSi3Q=s64","userId":"17507925689662955290"}},"outputId":"1e06df5c-673d-4220-9d31-8733fb3d3ae5"},"source":["cd /content/drive/MyDrive/NLP_Dissertation/DINO"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/NLP_Dissertation/DINO\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"-cD4ppmaN1zn","executionInfo":{"status":"ok","timestamp":1630492383988,"user_tz":-60,"elapsed":98800,"user":{"displayName":"varma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0mykgB2BlfeZ8lmORSdRPDRvODaQ8LpLMBHSi3Q=s64","userId":"17507925689662955290"}},"outputId":"62ec0f88-ac83-4960-8a6b-ab0b27edaf0f"},"source":["pip install -r requirements.txt"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting numpy==1.19\n","  Downloading numpy-1.19.0-cp37-cp37m-manylinux2010_x86_64.whl (14.6 MB)\n","\u001b[K     |████████████████████████████████| 14.6 MB 118 kB/s \n","\u001b[?25hCollecting torch==1.5.0\n","  Downloading https://download.pytorch.org/whl/cu92/torch-1.5.0%2Bcu92-cp37-cp37m-linux_x86_64.whl (603.7 MB)\n","\u001b[K     |████████████████████████████████| 603.7 MB 28 kB/s \n","\u001b[?25hCollecting torchvision==0.6.0\n","  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.6.0%2Bcu92-cp37-cp37m-linux_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 38.7 MB/s \n","\u001b[?25hCollecting transformers==4.2.1\n","  Downloading transformers-4.2.1-py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 49.4 MB/s \n","\u001b[?25hCollecting tqdm==4.49.0\n","  Downloading tqdm-4.49.0-py2.py3-none-any.whl (69 kB)\n","\u001b[K     |████████████████████████████████| 69 kB 9.4 MB/s \n","\u001b[?25hCollecting scikit-learn==0.24.1\n","  Downloading scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n","\u001b[K     |████████████████████████████████| 22.3 MB 204 kB/s \n","\u001b[?25hCollecting datasets==1.6.0\n","  Downloading datasets-1.6.0-py3-none-any.whl (202 kB)\n","\u001b[K     |████████████████████████████████| 202 kB 64.5 MB/s \n","\u001b[?25hCollecting openai==0.6.3\n","  Downloading openai-0.6.3.tar.gz (158 kB)\n","\u001b[K     |████████████████████████████████| 158 kB 91.4 MB/s \n","\u001b[?25hCollecting scipy==1.6.2\n","  Downloading scipy-1.6.2-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n","\u001b[K     |████████████████████████████████| 27.4 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.0->-r requirements.txt (line 3)) (0.16.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6.0->-r requirements.txt (line 4)) (7.1.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r requirements.txt (line 5)) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r requirements.txt (line 5)) (21.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 54.2 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r requirements.txt (line 5)) (2019.12.20)\n","Collecting tokenizers==0.9.4\n","  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 54.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r requirements.txt (line 5)) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r requirements.txt (line 5)) (4.6.4)\n","Collecting threadpoolctl>=2.0.0\n","  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1->-r requirements.txt (line 7)) (1.0.1)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 93.0 MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.0->-r requirements.txt (line 8)) (1.1.5)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.0->-r requirements.txt (line 8)) (0.70.12.2)\n","Collecting fsspec\n","  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n","\u001b[K     |████████████████████████████████| 119 kB 75.5 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.0->-r requirements.txt (line 8)) (3.0.0)\n","Collecting huggingface-hub<0.1.0\n","  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 8.8 MB/s \n","\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets==1.6.0->-r requirements.txt (line 8)) (0.3.4)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets==1.6.0->-r requirements.txt (line 8)) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==4.2.1->-r requirements.txt (line 5)) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r requirements.txt (line 5)) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r requirements.txt (line 5)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r requirements.txt (line 5)) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r requirements.txt (line 5)) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.2.1->-r requirements.txt (line 5)) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.6.0->-r requirements.txt (line 8)) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets==1.6.0->-r requirements.txt (line 8)) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets==1.6.0->-r requirements.txt (line 8)) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.1->-r requirements.txt (line 5)) (7.1.2)\n","Building wheels for collected packages: openai\n","  Building wheel for openai (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai: filename=openai-0.6.3-py3-none-any.whl size=170224 sha256=c80dcd406161bb34a607e851d0502f259cec1f61218163818b91757d7aca1346\n","  Stored in directory: /root/.cache/pip/wheels/b0/c2/00/2c212d8e68b7aae238e29e6aa54dee3bf98dd821249e74f5fa\n","Successfully built openai\n","Installing collected packages: tqdm, numpy, xxhash, torch, tokenizers, threadpoolctl, scipy, sacremoses, huggingface-hub, fsspec, transformers, torchvision, scikit-learn, openai, datasets\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.62.0\n","    Uninstalling tqdm-4.62.0:\n","      Successfully uninstalled tqdm-4.62.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.10.0+cu102\n","    Uninstalling torchvision-0.10.0+cu102:\n","      Successfully uninstalled torchvision-0.10.0+cu102\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.5.0+cu92 which is incompatible.\n","tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.19.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed datasets-1.6.0 fsspec-2021.8.1 huggingface-hub-0.0.16 numpy-1.19.0 openai-0.6.3 sacremoses-0.0.45 scikit-learn-0.24.1 scipy-1.6.2 threadpoolctl-2.2.0 tokenizers-0.9.4 torch-1.5.0+cu92 torchvision-0.6.0+cu92 tqdm-4.49.0 transformers-4.2.1 xxhash-2.0.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BnsdnmDieNyY","executionInfo":{"status":"ok","timestamp":1630492526916,"user_tz":-60,"elapsed":70561,"user":{"displayName":"varma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0mykgB2BlfeZ8lmORSdRPDRvODaQ8LpLMBHSi3Q=s64","userId":"17507925689662955290"}},"outputId":"619440cb-0dfa-4354-baa8-817696dd0bad"},"source":["!pip install torchtext"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (0.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.49.0)\n","Collecting torch==1.9.0\n","  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n","\u001b[K     |████████████████████████████████| 831.4 MB 2.0 kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext) (3.7.4.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n","Installing collected packages: torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.5.0+cu92\n","    Uninstalling torch-1.5.0+cu92:\n","      Successfully uninstalled torch-1.5.0+cu92\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.6.0+cu92 requires torch==1.5.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n","Successfully installed torch-1.9.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"DQMfglOBWmrU"},"source":["# Import libraries"]},{"cell_type":"code","metadata":{"id":"gih7PXpQWlVj"},"source":["import pandas as pd\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UK-0pVy9Wtei"},"source":["# Initial trail runs and code testing"]},{"cell_type":"code","metadata":{"id":"du5pIj2bS-vk"},"source":["#!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/dino.py --help"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H2tjNqYON4dE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629201840260,"user_tz":-60,"elapsed":1795519,"user":{"displayName":"varma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0mykgB2BlfeZ8lmORSdRPDRvODaQ8LpLMBHSi3Q=s64","userId":"17507925689662955290"}},"outputId":"c6828038-0c8b-44b7-a4f9-42abed750000"},"source":["#for 3 classes with default sts pattern\n","!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/dino.py \\\n"," --output_dir /content/drive/MyDrive/NLP_Dissertation/DINO/output \\\n"," --task_file /content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli.json \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_cordeiro.txt \\\n"," --input_file_type plain \\\n"," --num_entries_per_input_and_label 5\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Parameters: Namespace(allow_newlines_in_outputs=False, batch_size=None, date='17/08/2021 11:34:05', decay_constant=100, input_file='/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_cordeiro.txt', input_file_type='plain', keep_outputs_without_eos=False, max_output_length=40, min_num_tokens=-1, min_num_words=-1, model_name='gpt2-xl', no_cuda=False, num_entries_per_input_and_label=5, num_entries_per_label=None, openai_api_key=None, output_dir='/content/drive/MyDrive/NLP_Dissertation/DINO/output', remove_duplicates=False, remove_identical_pairs=False, seed=42, task_file='/content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli.json', top_k=5, top_p=0.9)\n","Done loading 270 inputs from file '/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_cordeiro.txt'\n","Starting dataset generation with DINO...\n","Dataset Entries:   0% 0/270 [00:00<?, ?it/s]2021-08-17 11:35:48.944662: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","Dataset Entries: 100% 270/270 [28:11<00:00,  6.27s/it]\n","Dataset generation complete, dataset contains 3310 entries\n","Done saving dataset to file '/content/drive/MyDrive/NLP_Dissertation/DINO/output/sts-dataset.jsonl'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FqocJ00G9eD_"},"source":["!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/postprocess_dataset.py \\\n"," --output_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/sts-dataset-pp.jsonl \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/sts-dataset.jsonl\n"," "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hgk0uZHm4IGf","executionInfo":{"status":"ok","timestamp":1629208101154,"user_tz":-60,"elapsed":2061317,"user":{"displayName":"varma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0mykgB2BlfeZ8lmORSdRPDRvODaQ8LpLMBHSi3Q=s64","userId":"17507925689662955290"}},"outputId":"dd76f751-3e1f-4167-e467-5d6a849560e9"},"source":["#for 3 classes with sts-nc-nli-1 pattern\n","!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/dino.py \\\n"," --output_dir /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-1 \\\n"," --task_file /content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli-1.json \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_cordeiro.txt \\\n"," --input_file_type plain \\\n"," --num_entries_per_input_and_label 10"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Parameters: Namespace(allow_newlines_in_outputs=False, batch_size=None, date='17/08/2021 13:14:00', decay_constant=100, input_file='/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_cordeiro.txt', input_file_type='plain', keep_outputs_without_eos=False, max_output_length=40, min_num_tokens=-1, min_num_words=-1, model_name='gpt2-xl', no_cuda=False, num_entries_per_input_and_label=10, num_entries_per_label=None, openai_api_key=None, output_dir='/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-1', remove_duplicates=False, remove_identical_pairs=False, seed=42, task_file='/content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli-1.json', top_k=5, top_p=0.9)\n","Done loading 270 inputs from file '/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_cordeiro.txt'\n","Starting dataset generation with DINO...\n","Dataset Entries:   0% 0/270 [00:00<?, ?it/s]2021-08-17 13:15:02.784229: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n","Dataset Entries: 100% 270/270 [33:18<00:00,  7.40s/it]\n","Dataset generation complete, dataset contains 7277 entries\n","Done saving dataset to file '/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-1/sts-dataset.jsonl'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PKX0jklTNOAm"},"source":["!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/postprocess_dataset.py \\\n"," --output_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-1/sts-dataset-pp.jsonl \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-1/sts-dataset.jsonl"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sSBJMIQOvt9n"},"source":["# Dataset generation for default Pattern and Whole NC set. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qV4UfkSjvt9w","executionInfo":{"status":"ok","timestamp":1630497524201,"user_tz":-60,"elapsed":4983848,"user":{"displayName":"varma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0mykgB2BlfeZ8lmORSdRPDRvODaQ8LpLMBHSi3Q=s64","userId":"17507925689662955290"}},"outputId":"151d5f76-816c-4ae6-d08d-9645d2438818"},"source":["#for 3 classes with sts-nc-nli-1 pattern (whole set)\n","!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/dino.py \\\n"," --output_dir /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-default-combined \\\n"," --task_file /content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli.json \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt \\\n"," --input_file_type plain \\\n"," --num_entries_per_input_and_label 7"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameters: Namespace(allow_newlines_in_outputs=False, batch_size=None, date='01/09/2021 10:35:43', decay_constant=100, input_file='/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt', input_file_type='plain', keep_outputs_without_eos=False, max_output_length=40, min_num_tokens=-1, min_num_words=-1, model_name='gpt2-xl', no_cuda=False, num_entries_per_input_and_label=7, num_entries_per_label=None, openai_api_key=None, output_dir='/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-default-combined', remove_duplicates=False, remove_identical_pairs=False, seed=42, task_file='/content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli.json', top_k=5, top_p=0.9)\n","Done loading 674 inputs from file '/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt'\n","Downloading: 100% 1.04M/1.04M [00:00<00:00, 2.84MB/s]\n","Downloading: 100% 456k/456k [00:00<00:00, 1.73MB/s]\n","Downloading: 100% 787/787 [00:00<00:00, 571kB/s]\n","Downloading: 100% 6.43G/6.43G [01:34<00:00, 68.0MB/s]\n","Starting dataset generation with DINO...\n","Dataset Entries: 100% 674/674 [1:20:37<00:00,  7.18s/it]\n","Dataset generation complete, dataset contains 10065 entries\n","Done saving dataset to file '/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-default-combined/sts-dataset.jsonl'\n"]}]},{"cell_type":"code","metadata":{"id":"M27OVWLpvt9w"},"source":["df = pd.read_json('/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-default-combined/sts-dataset.jsonl', lines=True)\n","df['index'] = df.index\n","df.to_json('/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-default-combined/sts-dataset-index.jsonl', orient='records', lines=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B5YhMkq7vt9w"},"source":["!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/postprocess_dataset.py \\\n"," --output_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-default-combined/sts-nc-nli-comb-dataset-pp.jsonl \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-default-combined/sts-dataset-index.jsonl"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FCrI2yzBUvyU"},"source":["# Dataset generation for Pattern-1 and Whole NC set. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8zdn4WPS8ZbJ","executionInfo":{"status":"ok","timestamp":1630502583695,"user_tz":-60,"elapsed":5057812,"user":{"displayName":"varma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0mykgB2BlfeZ8lmORSdRPDRvODaQ8LpLMBHSi3Q=s64","userId":"17507925689662955290"}},"outputId":"c19e8bb3-dec8-452e-fe15-417e53e1099c"},"source":["#for 3 classes with sts-nc-nli-1 pattern (whole set)\n","!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/dino.py \\\n"," --output_dir /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-1-combined \\\n"," --task_file /content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli-1.json \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt \\\n"," --input_file_type plain \\\n"," --num_entries_per_input_and_label 7"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameters: Namespace(allow_newlines_in_outputs=False, batch_size=None, date='01/09/2021 11:58:46', decay_constant=100, input_file='/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt', input_file_type='plain', keep_outputs_without_eos=False, max_output_length=40, min_num_tokens=-1, min_num_words=-1, model_name='gpt2-xl', no_cuda=False, num_entries_per_input_and_label=7, num_entries_per_label=None, openai_api_key=None, output_dir='/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-1-combined', remove_duplicates=False, remove_identical_pairs=False, seed=42, task_file='/content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli-1.json', top_k=5, top_p=0.9)\n","Done loading 674 inputs from file '/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt'\n","Starting dataset generation with DINO...\n","Dataset Entries: 100% 674/674 [1:22:41<00:00,  7.36s/it]\n","Dataset generation complete, dataset contains 10588 entries\n","Done saving dataset to file '/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-1-combined/sts-dataset.jsonl'\n"]}]},{"cell_type":"code","metadata":{"id":"XMfiqBmPUY7Z"},"source":["df = pd.read_json('/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-1-combined/sts-dataset.jsonl', lines=True)\n","df['index'] = df.index\n","df.to_json('/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-1-combined/sts-dataset-index.jsonl', orient='records', lines=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UE3QfwpHJkv8"},"source":["!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/postprocess_dataset.py \\\n"," --output_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-1-combined/sts-nc-nli-comb-dataset-pp.jsonl \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-1-combined/sts-dataset-index.jsonl"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9riUqXAjWJ-I"},"source":["# Dataset generation for Pattern-2 and Whole NC set. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-XguYcHaWJ-J","executionInfo":{"status":"ok","timestamp":1630507485069,"user_tz":-60,"elapsed":4900147,"user":{"displayName":"varma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0mykgB2BlfeZ8lmORSdRPDRvODaQ8LpLMBHSi3Q=s64","userId":"17507925689662955290"}},"outputId":"84e10c38-0c5a-4663-9ebd-301b6ffa0b38"},"source":["#for 3 classes with sts-nc-nli-1 pattern (whole set)\n","!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/dino.py \\\n"," --output_dir /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-2-combined \\\n"," --task_file /content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli-2.json \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt \\\n"," --input_file_type plain \\\n"," --num_entries_per_input_and_label 7"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameters: Namespace(allow_newlines_in_outputs=False, batch_size=None, date='01/09/2021 13:23:05', decay_constant=100, input_file='/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt', input_file_type='plain', keep_outputs_without_eos=False, max_output_length=40, min_num_tokens=-1, min_num_words=-1, model_name='gpt2-xl', no_cuda=False, num_entries_per_input_and_label=7, num_entries_per_label=None, openai_api_key=None, output_dir='/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-2-combined', remove_duplicates=False, remove_identical_pairs=False, seed=42, task_file='/content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli-2.json', top_k=5, top_p=0.9)\n","Done loading 674 inputs from file '/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt'\n","Starting dataset generation with DINO...\n","Dataset Entries: 100% 674/674 [1:20:47<00:00,  7.19s/it]\n","Dataset generation complete, dataset contains 11382 entries\n","Done saving dataset to file '/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-2-combined/sts-dataset.jsonl'\n"]}]},{"cell_type":"code","metadata":{"id":"VtCsCUbzWJ-K"},"source":["df = pd.read_json('/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-2-combined/sts-dataset.jsonl', lines=True)\n","df['index'] = df.index\n","df.to_json('/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-2-combined/sts-dataset-index.jsonl', orient='records', lines=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7X318QFTWJ-K"},"source":["!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/postprocess_dataset.py \\\n"," --output_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-2-combined/sts-nc-nli-comb-dataset-pp.jsonl \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-2-combined/sts-dataset-index.jsonl"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O3w2AsEpWV_M"},"source":["# Dataset generation for Pattern-3 and Whole NC set. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJNxHSYZWV_M","executionInfo":{"status":"ok","timestamp":1630512379576,"user_tz":-60,"elapsed":4893717,"user":{"displayName":"varma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0mykgB2BlfeZ8lmORSdRPDRvODaQ8LpLMBHSi3Q=s64","userId":"17507925689662955290"}},"outputId":"20c6acdf-4657-4837-911d-78511b018e84"},"source":["#for 3 classes with sts-nc-nli-1 pattern (whole set)\n","!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/dino.py \\\n"," --output_dir /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-3-combined \\\n"," --task_file /content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli-3.json \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt \\\n"," --input_file_type plain \\\n"," --num_entries_per_input_and_label 7"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameters: Namespace(allow_newlines_in_outputs=False, batch_size=None, date='01/09/2021 14:44:46', decay_constant=100, input_file='/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt', input_file_type='plain', keep_outputs_without_eos=False, max_output_length=40, min_num_tokens=-1, min_num_words=-1, model_name='gpt2-xl', no_cuda=False, num_entries_per_input_and_label=7, num_entries_per_label=None, openai_api_key=None, output_dir='/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-3-combined', remove_duplicates=False, remove_identical_pairs=False, seed=42, task_file='/content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli-3.json', top_k=5, top_p=0.9)\n","Done loading 674 inputs from file '/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt'\n","Starting dataset generation with DINO...\n","Dataset Entries: 100% 674/674 [1:20:45<00:00,  7.19s/it]\n","Dataset generation complete, dataset contains 10720 entries\n","Done saving dataset to file '/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-3-combined/sts-dataset.jsonl'\n"]}]},{"cell_type":"code","metadata":{"id":"OKU2cHHKWV_M"},"source":["import pandas as pd\n","df = pd.read_json('/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-3-combined/sts-dataset.jsonl', lines=True)\n","df['index'] = df.index\n","df.to_json('/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-3-combined/sts-dataset-index.jsonl', orient='records', lines=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKdPQ8spWV_M"},"source":["!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/postprocess_dataset.py \\\n"," --output_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-3-combined/sts-nc-nli-comb-dataset-pp.jsonl \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-3-combined/sts-dataset-index.jsonl"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zK78QQsbWbDO"},"source":["# Dataset generation for Pattern-4 and Whole NC set. "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i-3E9BeKWbDO","executionInfo":{"status":"ok","timestamp":1630517737616,"user_tz":-60,"elapsed":4999679,"user":{"displayName":"varma","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg0mykgB2BlfeZ8lmORSdRPDRvODaQ8LpLMBHSi3Q=s64","userId":"17507925689662955290"}},"outputId":"5e6de2c3-4849-4034-8002-f11a269edd68"},"source":["#for 3 classes with sts-nc-nli-1 pattern (whole set)\n","!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/dino.py \\\n"," --output_dir /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-4-combined \\\n"," --task_file /content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli-4.json \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt \\\n"," --input_file_type plain \\\n"," --num_entries_per_input_and_label 7"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Parameters: Namespace(allow_newlines_in_outputs=False, batch_size=None, date='01/09/2021 16:12:18', decay_constant=100, input_file='/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt', input_file_type='plain', keep_outputs_without_eos=False, max_output_length=40, min_num_tokens=-1, min_num_words=-1, model_name='gpt2-xl', no_cuda=False, num_entries_per_input_and_label=7, num_entries_per_label=None, openai_api_key=None, output_dir='/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-4-combined', remove_duplicates=False, remove_identical_pairs=False, seed=42, task_file='/content/drive/MyDrive/NLP_Dissertation/DINO/task_specs/sts-nc-nli-4.json', top_k=5, top_p=0.9)\n","Done loading 674 inputs from file '/content/drive/MyDrive/NLP_Dissertation/DINO/dataset/NC_combined.txt'\n","Starting dataset generation with DINO...\n","Dataset Entries: 100% 674/674 [1:22:36<00:00,  7.35s/it]\n","Dataset generation complete, dataset contains 11197 entries\n","Done saving dataset to file '/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-4-combined/sts-dataset.jsonl'\n"]}]},{"cell_type":"code","metadata":{"id":"gJLIRi4oWbDO"},"source":["import pandas as pd\n","df = pd.read_json('/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-4-combined/sts-dataset.jsonl', lines=True)\n","df['index'] = df.index\n","df.to_json('/content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-4-combined/sts-dataset-index.jsonl', orient='records', lines=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DnsMBvRQWbDO"},"source":["!python3 /content/drive/MyDrive/NLP_Dissertation/DINO/postprocess_dataset.py \\\n"," --output_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-4-combined/sts-nc-nli-comb-dataset-pp.jsonl \\\n"," --input_file /content/drive/MyDrive/NLP_Dissertation/DINO/output/nc-nli-4-combined/sts-dataset-index.jsonl"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zhKkHsY4GVGR"},"source":["# References"]},{"cell_type":"markdown","metadata":{"id":"JD5HrxRZIi-q"},"source":["1. https://github.com/timoschick/dino\n","\n","2. Schick, T., and Schütze, H.Generating datasets with pretrained language models.Computing Research Repository arXiv:2104.07540(2021)."]}]}